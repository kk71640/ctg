{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T08:10:23.896875Z",
     "start_time": "2020-04-01T08:10:22.751151Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# library\n",
    "\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as pat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random\n",
    "from collections import namedtuple\n",
    "import tensorboardX as tbx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "from utils.mylogger import NewLogger\n",
    "from utils.torchblock import Block\n",
    "\n",
    "random.seed(999)\n",
    "torch.manual_seed(999)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# config, logger, tensorboard\n",
    "\n",
    "config = {\n",
    "    'test_mode': False,\n",
    "    'model_name': '1layer_nopl_lr2e-4_dropout0.2_ksize4_weight10',\n",
    "    'num_epochs': 50,\n",
    "    'batch_size': 32,\n",
    "    'n_channels': 8,\n",
    "    'k_size': 4,\n",
    "    'd_rate': 0.2,\n",
    "    'lr': 2e-4,\n",
    "    'loss_weight': 10.0,\n",
    "    'uaph_threshold': 7.05\n",
    "}\n",
    "c = namedtuple('config_class', config.keys())(*config.values())\n",
    "\n",
    "logger = None\n",
    "logger = NewLogger(test=c.test_mode, result_path='./log/', model_name=c.model_name)\n",
    "\n",
    "logger.debug('=== config ===')\n",
    "for k, v in config.items() : logger.debug('%s %s' % (k, v)) \n",
    "logger.debug('==============')\n",
    "\n",
    "with open(os.path.join(logger.dir_path, 'config.json'), mode='w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T08:10:23.960744Z",
     "start_time": "2020-04-01T08:10:23.913989Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# CTG Dataset\n",
    "\n",
    "class CTGDataset(data.Dataset):\n",
    "    def __init__(self, fhr_path_list, toco_path_list, uaph_path, uaph_threshold):\n",
    "        self.fhr_path_list = fhr_path_list\n",
    "        self.toco_path_list = toco_path_list\n",
    "        self.uaph = pd.read_csv(uaph_path, header=None).values.reshape([-1])\n",
    "        self.uaph_threshold = uaph_threshold\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fhr_path_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fhr_data = self.path2tensor(self.fhr_path_list[index])\n",
    "        toco_data = self.path2tensor(self.toco_path_list[index])\n",
    "        \n",
    "        if self.uaph[index] < self.uaph_threshold:\n",
    "            label = torch.tensor([0., 1.])\n",
    "        else:\n",
    "            label = torch.tensor([1., 0.])\n",
    "        \n",
    "        uaph = self.uaph[index]\n",
    "        \n",
    "        fhr_data = (fhr_data - 135) / 25\n",
    "        return fhr_data, toco_data, label, uaph\n",
    "    \n",
    "    @staticmethod\n",
    "    def path2tensor(path):\n",
    "        np_data = pd.read_csv(path, header=None).values.reshape([-1])\n",
    "        np_data = np_data[-14400:]\n",
    "        nn_data = torch.from_numpy(np_data).to(torch.float).reshape(1, -1)\n",
    "        return nn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T08:10:23.974792Z",
     "start_time": "2020-04-01T08:10:23.963329Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# dataloader\n",
    "\n",
    "fhr_path_list = ['./data/ctu/ctu_csv/%s_fhr.csv' % i for i in range(1, 552 + 1)]\n",
    "toco_path_list = ['./data/ctu/ctu_csv/%s_toco.csv' % i for i in range(1, 552 + 1)]\n",
    "\n",
    "all_dataset = CTGDataset(fhr_path_list, toco_path_list, './data/ctu/uaph.csv', c.uaph_threshold)\n",
    "train_size = int(len(all_dataset) * 0.8)\n",
    "val_size = len(all_dataset) - train_size\n",
    "train_dataset, val_dataset = data.random_split(all_dataset, [train_size, val_size])\n",
    "\n",
    "dataloader = {\n",
    "    'train': data.DataLoader(train_dataset, batch_size=c.batch_size, \n",
    "                             shuffle=True, num_workers=4),\n",
    "    'val': data.DataLoader(val_dataset, batch_size=c.batch_size, \n",
    "                           shuffle=True, num_workers=4),\n",
    "}\n",
    "\n",
    "logger.debug('train_size:%s, val_size:%s' % (train_size, val_size))\n",
    "\n",
    "# iter(dataloader['train']).next()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def calc_statistics(pred, truth):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        pred(torch.tensor): 0 or 1\n",
    "        truth(torch.tensor): 0 or 1\n",
    "    \n",
    "    Returns:\n",
    "        tp, fp, fn, tn, tpr, tnr, prec, acc, f1\n",
    "    \"\"\"\n",
    "    \n",
    "    tp = int(torch.sum((pred == 1) & (truth == 1)))   \n",
    "    fp = int(torch.sum((pred == 1) & (truth == 0)))\n",
    "    fn = int(torch.sum((pred == 0) & (truth == 1))) \n",
    "    tn = int(torch.sum((pred == 0) & (truth == 0)))\n",
    "    \n",
    "    tpr = tp / (tp + fn) if tp + fn > 0 else -1\n",
    "    tnr = tn / (fp + tn) if fp + tn > 0 else -1\n",
    "    acc = (tp + tn) / (tp + fp + fn + tn) if tp + fp + fn + tn > 0 else -1\n",
    "    prec = tp / (tp + fp) if tp + fp > 0 else -1\n",
    "\n",
    "    try:\n",
    "        f1 = (2 * prec * tpr) / (tpr + prec)\n",
    "    except:\n",
    "        f1 = -1\n",
    "        \n",
    "    return tp, fp, fn, tn, tpr, tnr, acc, prec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        \n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_channels, k_size, d_rate):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.seq = nn.Sequential(\n",
    "            nn.MaxPool1d(4*10), # (1, 360)\n",
    "            \n",
    "            nn.Conv1d(1, n_channels, kernel_size=k_size, \n",
    "                      padding=k_size-1, padding_mode='circular'),\n",
    "            nn.BatchNorm1d(n_channels),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            #nn.MaxPool1d(2), #(n_chanels, 180)\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=d_rate),\n",
    "            nn.Linear(n_channels*360, 2),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# network, loss, optimizer\n",
    "\n",
    "logger.debug('network initializing')\n",
    "\n",
    "net = Net(n_channels=c.n_channels, k_size=c.k_size, d_rate=c.d_rate)\n",
    "net = net.to(device).apply(weights_init)\n",
    "weight = torch.tensor([1.0, c.loss_weight]).to(device)\n",
    "\n",
    "logger.debug('network initialized')\n",
    "\n",
    "criterion = nn.BCELoss(reduction='mean', weight=weight)\n",
    "optimizer = optim.Adam(net.parameters(), lr=c.lr, betas=(0.8, 0.999))\n",
    "\n",
    "logger.debug(net)\n",
    "\n",
    "#net(iter(dataloader['train']).next()[0].to(device)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T08:14:02.786203Z",
     "start_time": "2020-04-01T08:14:02.782156Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# execute\n",
    "\n",
    "writer = tbx.SummaryWriter(log_dir=logger.dir_path)\n",
    "\n",
    "for epoch in range(1, c.num_epochs+1):\n",
    "    \n",
    "    for phase in ['train', 'val']:\n",
    "        \n",
    "        phase_loss = 0\n",
    "        \n",
    "        epoch_pred_cls = torch.tensor([]).to(torch.long)\n",
    "        epoch_true_cls = torch.tensor([]).to(torch.long)\n",
    "        \n",
    "        if phase == 'train':\n",
    "            net.train()\n",
    "        else:\n",
    "            net.eval()\n",
    "        \n",
    "        if (epoch == 1) & (phase == 'train'):\n",
    "            continue\n",
    "        \n",
    "        for batch in dataloader[phase]:\n",
    "            inputs = batch[0].to(device)\n",
    "            labels = batch[2].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                _, pred_cls = torch.max(outputs, 1)\n",
    "                _, true_cls = torch.max(labels, 1)\n",
    "                \n",
    "                epoch_pred_cls = torch.cat([epoch_pred_cls, pred_cls.to('cpu')])\n",
    "                epoch_true_cls = torch.cat([epoch_true_cls, true_cls.to('cpu')])\n",
    "                \n",
    "                phase_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "        phase_loss /= len(dataloader[phase].dataset)\n",
    "        \n",
    "        logger.debug('epoch: {}, phase: {}, loss: {:.4f}'.format(\n",
    "                     epoch, phase, phase_loss))\n",
    "        tp, fp, fn, tn, tpr, tnr, acc, prec, f1 = \\\n",
    "            calc_statistics(epoch_pred_cls, epoch_true_cls)\n",
    "        \n",
    "        writer.add_scalars('loss', {phase: phase_loss}, epoch)\n",
    "        writer.add_scalars('statistics/tpr', {'%s_tpr' % phase: tpr}, epoch)\n",
    "        writer.add_scalars('statistics/tnr', {'%s_tnr' % phase: tnr}, epoch)\n",
    "\n",
    "        logger.info('epoch: {}, phase: {}, loss: {:.3f}'.format(epoch, phase, phase_loss))\n",
    "#         logger.info('[tp: %s fn: %s] [fp: %s tn: %s]' % (tp, fn, fp, tn))\n",
    "        logger.info('tpr: {:.3f}, tnr: {:.3f}'.format(tpr, tnr))\n",
    "#         logger.info('acc: {:.3f}, prec: {:.3f}, f1: {:.3f}'.format(acc, prec, f1))\n",
    "\n",
    "writer.close()\n",
    "logger.info('tensorboard --logdir %s' % os.path.abspath(logger.dir_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
