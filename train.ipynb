{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T08:10:23.896875Z",
     "start_time": "2020-04-01T08:10:22.751151Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as pat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "from utils.mylogger import NewLogger\n",
    "from utils.torchblock import Block\n",
    "from utils.json_utils import Json_Config\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-13 16:55:54 - ==== config ====\n",
      "2020-04-13 16:55:54 - model_name simple_model\n",
      "2020-04-13 16:55:54 - num_epochs 100\n",
      "2020-04-13 16:55:54 - batch_size 10\n",
      "2020-04-13 16:55:54 - loss_weight 10.0\n",
      "2020-04-13 16:55:54 - lr 0.0002\n",
      "2020-04-13 16:55:54 - ngpu 4\n",
      "2020-04-13 16:55:54 - num_workers 4\n",
      "2020-04-13 16:55:54 - uaph_path ./data/ctu/uaph.csv\n",
      "2020-04-13 16:55:54 - data_path ./data/ctu/ctu_csv/\n",
      "2020-04-13 16:55:54 - uaph_threshold 7.05\n",
      "2020-04-13 16:55:54 - ================\n",
      "2020-04-13 16:55:54 - dir_path: ./log/test\n"
     ]
    }
   ],
   "source": [
    "test_mode = True\n",
    "\n",
    "json_config = Json_Config('config.json')\n",
    "c = json_config.export_config()\n",
    "\n",
    "logger = None\n",
    "logger = NewLogger(test=test_mode, result_path='./log/', model_name=c.model_name)\n",
    "json_config.log_and_save(logger)\n",
    "logger.debug('dir_path: %s' % logger.dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T08:10:23.906640Z",
     "start_time": "2020-04-01T08:10:23.901905Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and c.ngpu > 0) else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "manualSeed = 999\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "logger.debug('seed: %s' % manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T08:10:23.960744Z",
     "start_time": "2020-04-01T08:10:23.913989Z"
    }
   },
   "outputs": [],
   "source": [
    "# CTG Dataset\n",
    "\n",
    "class CTGDataset(data.Dataset):\n",
    "    def __init__(self, fhr_path_list, toco_path_list, uaph_path, uaph_threshold):\n",
    "        self.fhr_path_list = fhr_path_list\n",
    "        self.toco_path_list = toco_path_list\n",
    "        self.uaph = pd.read_csv(uaph_path, header=None).values.reshape([-1])\n",
    "        self.uaph_threshold = uaph_threshold\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fhr_path_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fhr_data = self.path2tensor(self.fhr_path_list[index])\n",
    "        toco_data = self.path2tensor(self.toco_path_list[index])\n",
    "        \n",
    "        if self.uaph[index] < self.uaph_threshold:\n",
    "            label = torch.tensor([0., 1.])\n",
    "        else:\n",
    "            label = torch.tensor([1., 0.])\n",
    "        \n",
    "        uaph = self.uaph[index]\n",
    "        \n",
    "        return fhr_data, toco_data, label, uaph\n",
    "    \n",
    "    @staticmethod\n",
    "    def path2tensor(path):\n",
    "        np_data = pd.read_csv(path, header=None).values.reshape([-1])\n",
    "        np_data = np_data[-14400:]\n",
    "        nn_data = torch.from_numpy(np_data).to(torch.float).reshape(1, -1)\n",
    "        return nn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T08:10:23.974792Z",
     "start_time": "2020-04-01T08:10:23.963329Z"
    }
   },
   "outputs": [],
   "source": [
    "fhr_path_list = [os.path.join(c.data_path, '%s_fhr.csv' % i) for i in range(1, 552 + 1)]\n",
    "toco_path_list = [os.path.join(c.data_path, '%s_toco.csv' % i) for i in range(1, 552 + 1)]\n",
    "\n",
    "all_dataset = CTGDataset(fhr_path_list, toco_path_list, c.uaph_path, c.uaph_threshold)\n",
    "all_size = len(all_dataset)\n",
    "\n",
    "train_size = int(all_size * 0.8)\n",
    "val_size = all_size - train_size\n",
    "\n",
    "train_dataset, val_dataset = data.random_split(all_dataset, [train_size, val_size])\n",
    "\n",
    "dataloader = {\n",
    "    'train': data.DataLoader(train_dataset, batch_size=c.batch_size, \n",
    "                             shuffle=True, num_workers=c.num_workers),\n",
    "    'val': data.DataLoader(val_dataset, batch_size=c.batch_size, \n",
    "                           shuffle=True, num_workers=c.num_workers),\n",
    "}\n",
    "\n",
    "logger.debug('train_size:%s, val_size:%s' % (train_size, val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_statistics(pred, truth):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        pred(torch.tensor): 0 or 1\n",
    "        truth(torch.tensor): 0 or 1\n",
    "    \n",
    "    Returns:\n",
    "        tp, fp, fn, tn, tpr, tnr, prec, acc, f1\n",
    "    \"\"\"\n",
    "    \n",
    "    tp = int(torch.sum((pred == 1) & (truth == 1)))   \n",
    "    fp = int(torch.sum((pred == 1) & (truth == 0)))\n",
    "    fn = int(torch.sum((pred == 0) & (truth == 1))) \n",
    "    tn = int(torch.sum((pred == 0) & (truth == 0)))\n",
    "    \n",
    "    tpr = tp / (tp + fn) if tp + fn > 0 else -1\n",
    "    tnr = tn / (fp + tn) if fp + tn > 0 else -1\n",
    "    acc = (tp + tn) / (tp + fp + fn + tn) if tp + fp + fn + tn > 0 else -1\n",
    "    prec = tp / (tp + fp) if tp + fp > 0 else -1\n",
    "\n",
    "    try:\n",
    "        f1 = (2 * prec * tpr) / (tpr + prec)\n",
    "    except:\n",
    "        f1 = -1\n",
    "        \n",
    "    return tp, fp, fn, tn, tpr, tnr, acc, prec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        \n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.seq = nn.Sequential(\n",
    "            nn.MaxPool1d(4, stride=4, padding=0, dilation=1),\n",
    "            \n",
    "            nn.Conv1d(1, 10, kernel_size=15, padding=7, stride=1),\n",
    "            nn.BatchNorm1d(10),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(10, 10, kernel_size=15, padding=7, stride=1),\n",
    "            nn.BatchNorm1d(10),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, stride=2, padding=0, dilation=1),\n",
    "            \n",
    "            nn.Conv1d(10, 20, kernel_size=15, padding=7, stride=1),\n",
    "            nn.BatchNorm1d(20),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, stride=2, padding=0, dilation=1),\n",
    "            \n",
    "            nn.Conv1d(20, 40, kernel_size=15, padding=7, stride=1),\n",
    "            nn.BatchNorm1d(40),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, stride=2, padding=0, dilation=1),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            \n",
    "            nn.Linear(40 * 450, 60),\n",
    "            nn.Linear(60, 2),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(device)\n",
    "net.apply(weights_init)\n",
    "weight = torch.tensor([1.0, c.loss_weight]).to(device)\n",
    "\n",
    "criterion = nn.BCELoss(reduction='mean', weight=weight)\n",
    "optimizer = optim.Adam(net.parameters(), lr=c.lr, betas=(0.8, 0.999))\n",
    "\n",
    "logger.debug(net)\n",
    "\n",
    "net(iter(dataloader['train']).next()[0].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T08:14:02.786203Z",
     "start_time": "2020-04-01T08:14:02.782156Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_list = {'train': [None], 'val': []}\n",
    "tpr_list= {'train': [None], 'val': []}\n",
    "tnr_list= {'train': [None], 'val': []}\n",
    "\n",
    "for epoch in range(1, c.num_epochs+1):\n",
    "    \n",
    "    for phase in ['train', 'val']:\n",
    "        \n",
    "        phase_loss = 0\n",
    "        \n",
    "        epoch_pred_cls = torch.tensor([]).to(torch.long)\n",
    "        epoch_true_cls = torch.tensor([]).to(torch.long)\n",
    "        \n",
    "        if phase == 'train':\n",
    "            net.train()\n",
    "        else:\n",
    "            net.eval()\n",
    "        \n",
    "        if (epoch == 1) & (phase == 'train'):\n",
    "            continue\n",
    "        \n",
    "        for i, batch in enumerate(tqdm(dataloader[phase]), 0):\n",
    "            inputs = batch[0].to(device)\n",
    "            labels = batch[2].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                _, pred_cls = torch.max(outputs, 1)\n",
    "                _, true_cls = torch.max(labels, 1)\n",
    "                \n",
    "                epoch_pred_cls = torch.cat([epoch_pred_cls, pred_cls.to('cpu')])\n",
    "                epoch_true_cls = torch.cat([epoch_true_cls, true_cls.to('cpu')])\n",
    "                \n",
    "                phase_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "        phase_loss /= len(dataloader[phase].dataset)\n",
    "        \n",
    "        logger.debug('epoch: {}, phase: {}, loss: {:.4f}'.format(\n",
    "                     epoch, phase, phase_loss))\n",
    "        tp, fp, fn, tn, tpr, tnr, acc, prec, f1 = \\\n",
    "            calc_statistics(epoch_pred_cls, epoch_true_cls)\n",
    "        \n",
    "        logger.debug('[tp: %s fn: %s] [fp: %s tn: %s]' % (tp, fn, fp, tn))\n",
    "        logger.debug('tpr: {:.3f}, tnr: {:.3f}'.format(tpr, tnr))\n",
    "        logger.debug('acc: {:.3f}, prec: {:.3f}, f1: {:.3f}'.format(acc, prec, f1))\n",
    "    \n",
    "        loss_list[phase] += [phase_loss]\n",
    "        tpr_list[phase] += [tpr]\n",
    "        tnr_list[phase] += [tnr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(loss_list['train'][1:], label='train')\n",
    "plt.plot(loss_list['val'][1:], label='val')\n",
    "plt.legend()\n",
    "plt.title('train: {:.4f} val: {:.4f}'.format(\n",
    "            loss_list['train'][-1], loss_list['val'][-1]))\n",
    "plt.savefig(os.path.join(logger.dir_path, 'loss.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(tpr_list['train'][1:], label='train_tpr')\n",
    "plt.plot(tpr_list['val'][1:], label='val_tpr')\n",
    "plt.plot(tnr_list['train'][1:], label='train_tnr')\n",
    "plt.plot(tnr_list['val'][1:], label='val_tnr')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('train_tpr: {:.4f}, val_tpr: {:.4f}, train_tnr: {:.4f}, val_tnr: {:.4f},'.format(\n",
    "            tpr_list['train'][-1], tpr_list['val'][-1], \n",
    "            tnr_list['train'][-1], tnr_list['val'][-1]))\n",
    "plt.savefig(os.path.join(logger.dir_path, 'tpr_tnr.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewer(index, dataset, min_length):\n",
    "    \"\"\"\n",
    "    visualize fetal heart rate\n",
    "    \n",
    "    Args:\n",
    "        index (int):\n",
    "        dataset (list):\n",
    "        min_length (int): visualizing duration(min) in an image\n",
    "    \"\"\"\n",
    "    \n",
    "    fhr = dataset[index][0].reshape(-1)\n",
    "    fhr = np.where(fhr == 0.0, np.nan, fhr)\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    mpl.rcParams['axes.xmargin'] = 0\n",
    "    mpl.rcParams['axes.ymargin'] = 0\n",
    "    \n",
    "    for i in range(3):\n",
    "        ax = plt.subplot(3, 1, i+1)\n",
    "\n",
    "        rec = pat.Rectangle(xy=(0, 110), width=min_length*240, height=50,\n",
    "                            color=\"whitesmoke\", alpha=1)\n",
    "        ax.add_patch(rec)\n",
    "\n",
    "        for j in range(min_length):\n",
    "           ax.axvline(x=j*240, color=\"gray\")\n",
    "\n",
    "        start = (i - 3) * min_length\n",
    "        end = (i - 2) * min_length\n",
    "\n",
    "        ax.plot(fhr[start*240: end*240-1])\n",
    "        \n",
    "        uaph = dataset[index][3]\n",
    "\n",
    "        ax.set_title('UApH {:.2f}, {} ~ {} min'.format(uaph, start, end))\n",
    "        \n",
    "        ax.set_xlim([0, min_length*240])\n",
    "        ax.set_ylim([40,220])\n",
    "        \n",
    "        plt.xticks(color=\"None\")\n",
    "\n",
    "# viewer(0, all_dataset, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
